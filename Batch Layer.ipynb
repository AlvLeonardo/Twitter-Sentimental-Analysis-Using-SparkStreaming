{"cells":[{"cell_type":"code","source":["from pyspark.sql.functions import when, lit, col, from_unixtime, regexp_replace, date_format, year, month, dayofmonth, regexp_extract\nfrom pyspark.sql.types import StructType, StructField, LongType, StringType, TimestampType\n \ninputPath = \"/mnt/rawleonardo/rawzone/Twitter.csv\"\n \nListaPos = r\":\\)|:\\]|:P|:p|:s|:d|:D|:\\}|;\\)|;\\]|;P|;p|;s|;d|;D|;\\}|=\\)|=\\]|=P|=p|=d|=D|=\\}|=S|:-\\)|:-\\]|:-P|:-p|:-s|:-d|:-D|:-\\}|;-\\)|;-\\]|;-P|;-p|;-s|;-d|;-D|;-\\}|=-\\)|=-\\]|=-P|=-p|=-d|=-D|=-\\}|=-S|: \\)|\\(:|\\( :|:- \\)|😂|❤️|😍|🤣|😊|🙏|💕|😘|👍|😅|👏|😁|🔥|💖|😆|💪|😉|👌|🤗|😎|😇|🌹|🎉|💞|✌️|✨|😌|🌸|🙌|😋|😏|🙂|🤩|😄|😀|💯|🤭|❣️|😜|🙋|🤪|👊|💃|😚|😝|🙃|🍀|🌷|😻|✅|🌈|😈|🤘|✔️|💐|🎊|💘|🌺\"\n \nListaNeg = r\":\\(|:\\/|:c|:\\\\|:C|:\\[|;\\(|;\\/|;c|;\\\\|;C|;\\[|=\\(|=\\/|=c|=\\\\|=C|=\\[|:-\\(|:-\\/|:-c|:-\\\\|:-C|:-\\[|;-\\(|;-\\/|;-c|;-\\\\|;-C|;-\\[|=-\\(|=-\\/|=-c|=-\\\\|=-C|=-\\[|😭|😢|🤔|🙄|😔|🤦|😱|😒|😪|😑|😞|😩|😡|😥|😳|✋|😴|😬|😓|😣|🏃|☹️|😠|🥺|🤬\"\n \nrm_links = \"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\"\n \nnomes = \"Bolsonaro|bolsonaro|bonoro|Bonoro|bozo|Bozo|Jair|jair|bozonaro|Bozonaro|jairbolsonaro|Jairbolsonaro\"\n \n# Definindo o Schema\nschema = StructType(\n    [\n    StructField(\"id\", StringType()),\n    StructField(\"text\", StringType()),\n    StructField(\"datetime\", TimestampType())\n    ]\n)\n \ndf_b = (spark.read.csv(inputPath, schema = schema, sep = \";\")) \n \ndf_b = df_b.withColumn(\"datetime\", date_format(col(\"datetime\"), \"yyyy-MM-dd hh:mm:ss\")).withColumnRenamed(\"datetime\", \"tweet_data\") \\\n           .withColumn(\"text\", regexp_replace(col(\"text\"), rm_links, \"\")) \\\n           .withColumn(\"Simbolo\", regexp_extract(col(\"text\"), f'{ListaPos}|{ListaNeg}', 0)) \\\n           .withColumn(\"Sentimento\", when(col(\"Simbolo\").rlike(ListaPos), \"Positivo\").when(col(\"Simbolo\").rlike(ListaNeg), \"Negativo\").otherwise(\"Neutro\")) \\\n           .withColumn(\"Ano\", year(\"tweet_data\")).withColumn(\"Mes\", month(\"tweet_data\")).withColumn(\"Dia\", dayofmonth(\"tweet_data\")) \\\n           .filter(col(\"text\").rlike(nomes))\n \ndisplay(df_b)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b186b28-c430-46ac-b4b6-f67a5c9bde90"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Salvar o dataframe já processado em Parquet, sendo particionados por \"Ano/Mês/Dia\"\n \ndf_b.write.mode('overwrite').partitionBy(\"Ano\", \"Mes\", \"Dia\").format(\"parquet\").save(\"/mnt/rawleonardo/refzone/Twitter2018\") # Particionando o Arquivo em Ano/Mes/Dia e Salvando"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88ce1900-8de8-4c00-8bbe-b989ffa1c238"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Juntar todos os arquivos particionados em um Parquet só, facilitando a leitura em PowerBI\n \ndf = spark.read.parquet(\"/mnt/rawleonardo/refzone/Twitter2018/Ano=2018\")\ndf = df.coalesce(1).write.parquet(\"mnt/rawleonardo/refzone/Twitter2018/Coalesce2018\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f303e33b-aab3-4142-b9e7-6e7d91ee8435"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Batch Layer","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":149137146620354}},"nbformat":4,"nbformat_minor":0}
